@inproceedings{10099815,
 author = {Kit, Brentton Wong Swee and Joseph, Minnu Helen},
 booktitle = {2023 15th International Conference on Developments in eSystems Engineering (DeSE)},
 doi = {10.1109/DeSE58274.2023.10099815},
 keywords = {Industries;Sentiment analysis;Machine learning;Companies;Predictive models;Motion pictures;Decision trees;Sentiment Analysis;Aspect-Based;Text Analysis;Machine Learning;Polarity;Movie;Reviews},
 number = {},
 pages = {237-243},
 title = {Aspect-Based Sentiment Analysis on Movie Reviews},
 volume = {},
 year = {2023}
}

@article{10151883,
 author = {Yu, Yang and Dinh, Duy-Tai and Nguyen, Ba-Hung and Yu, Fangyu and Huynh, Van-Nam},
 doi = {10.1109/ACCESS.2023.3285864},
 journal = {IEEE Access},
 keywords = {Games;Sentiment analysis;Task analysis;Transformers;Resource management;Bit error rate;Analytical models;Esports;topic modeling;prevalence analysis;sentiment analysis;steam},
 number = {},
 pages = {61161-61172},
 title = {Mining Insights From Esports Game Reviews With an Aspect-Based Sentiment Analysis Framework},
 volume = {11},
 year = {2023}
}

@inproceedings{10191634,
 author = {Yu, Yongxin and Zhao, Minyi and Zhou, Shuigeng},
 booktitle = {2023 International Joint Conference on Neural Networks (IJCNN)},
 doi = {10.1109/IJCNN54540.2023.10191634},
 keywords = {Sentiment analysis;Semantics;Neural networks;Training data;Predictive models;Data augmentation;Data models;Aspect-based sentiment analysis;Aspect sentiment quad prediction;Data augmentation;Self-training},
 number = {},
 pages = {1-8},
 title = {Boosting Aspect Sentiment Quad Prediction by Data Augmentation and Self-Training},
 volume = {},
 year = {2023}
}

@inproceedings{10394369,
 author = {Lil, Zhijun and Yang, Zhenyu and Li, Xiaoyang and Li, Yiwen},
 booktitle = {2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
 doi = {10.1109/SMC53992.2023.10394369},
 keywords = {Technological innovation;Correlation;Semantics;Natural languages;Tagging;Generators;Task analysis},
 number = {},
 pages = {2118-2125},
 title = {Two-Stage Aspect Sentiment Quadruple Prediction Based on MRC and Text Generation},
 volume = {},
 year = {2023}
}

@inproceedings{10499502,
 author = {Wang, Yajing and Luo, Zongwei},
 booktitle = {2023 International Conference on High Performance Big Data and Intelligent Systems (HDIS)},
 doi = {10.1109/HDIS60872.2023.10499502},
 keywords = {Sentiment analysis;Analytical models;Costs;Reviews;Big Data;Data models;Task analysis;large language models;prompting strategies;sentiment analysis;implicit sentiment analysis},
 number = {},
 pages = {1-7},
 title = {Enhance Multi-Domain Sentiment Analysis of Review Texts Through Prompting Strategies},
 volume = {},
 year = {2023}
}

@article{9996141,
 author = {Zhang, Wenxuan and Li, Xin and Deng, Yang and Bing, Lidong and Lam, Wai},
 doi = {10.1109/TKDE.2022.3230975},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 keywords = {Task analysis;Sentiment analysis;Compounds;Data mining;Taxonomy;Analytical models;Systematics;Aspect-based sentiment analysis;opinion mining;pre-trained language models;sentiment analysis},
 title = {A Survey on Aspect-Based Sentiment Analysis: Tasks, Methods, and Challenges},
 volume = {35},
 year = {2023}
}

@inproceedings{arianto-budi-2020-aspect,
 address = {Hanoi, Vietnam},
 author = {Arianto, Dian  and
Budi, Indra},
 booktitle = {Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation},
 editor = {Nguyen, Minh Le  and
Luong, Mai Chi  and
Song, Sanghoun},
 month = {October},
 pages = {359--367},
 publisher = {Association for Computational Linguistics},
 title = {Aspect-based Sentiment Analysis on {I}ndonesia{'}s Tourism Destinations Based on {G}oogle Maps User Code-Mixed Reviews (Study Case: Borobudur and Prambanan Temples)},
 url = {https://aclanthology.org/2020.paclic-1.41},
 year = {2020}
}

@inproceedings{bai-etal-2024-compound,
 abstract = {Aspect-based sentiment analysis (ABSA) aims to predict aspect-based elements from the given text, mainly including four elements, i.e., aspect category, sentiment polarity, aspect term, and opinion term. Extracting pair, triple, or quad of elements is defined as compound ABSA. Due to its challenges and practical applications, such a compound scenario has become an emerging topic. Recently, large language models (LLMs), e.g. ChatGPT and LLaMA, present impressive abilities in tackling various human instructions. In this work, we are particularly curious whether LLMs still possess superior performance in handling compound ABSA tasks. To assess the performance of LLMs, we design a novel framework, called ChatABSA. Concretely, we design two strategies: constrained prompts, to automatically organize the returned predictions; post-processing, to better evaluate the capability of LLMs in recognition of implicit information. The overall evaluation involves 5 compound ABSA tasks and 8 publicly available datasets. We compare LLMs with few-shot supervised baselines and fully supervised baselines, including corresponding state-of-the-art (SOTA) models on each task. Experimental results show that ChatABSA exhibits excellent aspect-based sentiment analysis capabilities and overwhelmingly beats few-shot supervised methods under the same few-shot settings. Surprisingly, it can even outperform fully supervised methods in some cases. However, in most cases, it underperforms fully supervised methods, and there is still a huge gap between its performance and the SOTA method. Moreover, we also conduct more analyses to gain a deeper understanding of its sentiment analysis capabilities.},
 address = {Miami, Florida, USA},
 author = {Bai, Yinhao  and
Han, Zhixin  and
Zhao, Yuhua  and
Gao, Hang  and
Zhang, Zhuowei  and
Wang, Xunzhi  and
Hu, Mengting},
 booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
 doi = {10.18653/v1/2024.findings-emnlp.460},
 editor = {Al-Onaizan, Yaser  and
Bansal, Mohit  and
Chen, Yun-Nung},
 month = {November},
 pages = {7836--7861},
 publisher = {Association for Computational Linguistics},
 title = {Is Compound Aspect-Based Sentiment Analysis Addressed by {LLM}s?},
 url = {https://aclanthology.org/2024.findings-emnlp.460/},
 year = {2024}
}

@misc{brown2020language,
 archiveprefix = {arXiv},
 author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
 eprint = {2005.14165},
 primaryclass = {cs.CL},
 title = {Language Models are Few-Shot Learners},
 year = {2020}
}

@inproceedings{cai-etal-2020-aspect,
 address = {Barcelona, Spain (Online)},
 author = {Cai, Hongjie  and
Tu, Yaofeng  and
Zhou, Xiangsheng  and
Yu, Jianfei  and
Xia, Rui},
 booktitle = {Proceedings of the 28th International Conference on Computational Linguistics},
 doi = {10.18653/v1/2020.coling-main.72},
 editor = {Scott, Donia  and
Bel, Nuria  and
Zong, Chengqing},
 month = {December},
 pages = {833--843},
 publisher = {International Committee on Computational Linguistics},
 title = {Aspect-Category based Sentiment Analysis with Hierarchical Graph Convolutional Network},
 url = {https://aclanthology.org/2020.coling-main.72},
 year = {2020}
}

@article{Chu2022,
 author = {M. Chu and Y. Chen and L. Yang and J. Wang},
 doi = {10.3389/fpsyg.2022.1029945},
 journal = {Frontiers in Psychology},
 title = {Language interpretation in travel guidance platform: Text mining and sentiment analysis of TripAdvisor reviews},
 url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2022.1029945/full},
 volume = {13},
 year = {2022}
}

@inproceedings{dai-etal-2023-gpt,
 address = {Toronto, Canada},
 author = {Dai, Damai  and
Sun, Yutao  and
Dong, Li  and
Hao, Yaru  and
Ma, Shuming  and
Sui, Zhifang  and
Wei, Furu},
 booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
 doi = {10.18653/v1/2023.findings-acl.247},
 editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
 month = {July},
 pages = {4005--4019},
 publisher = {Association for Computational Linguistics},
 title = {Why Can {GPT} Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers},
 url = {https://aclanthology.org/2023.findings-acl.247},
 year = {2023}
}

@article{Dong2023ASF,
 author = {Qingxiu Dong and Lei Li and Damai Dai and Ce Zheng and Zhiyong Wu and Baobao Chang and Xu Sun and Jingjing Xu and Lei Li and Zhifang Sui},
 journal = {ArXiv},
 title = {A Survey for In-context Learning},
 url = {https://api.semanticscholar.org/CorpusID:263886074},
 volume = {abs/2301.00234},
 year = {2023}
}

@inproceedings{fei-etal-2023-reasoning,
 address = {Toronto, Canada},
 author = {Fei, Hao  and
Li, Bobo  and
Liu, Qian  and
Bing, Lidong  and
Li, Fei  and
Chua, Tat-Seng},
 booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
 doi = {10.18653/v1/2023.acl-short.101},
 editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
 month = {July},
 pages = {1171--1182},
 publisher = {Association for Computational Linguistics},
 title = {Reasoning Implicit Sentiment with Chain-of-Thought Prompting},
 url = {https://aclanthology.org/2023.acl-short.101},
 year = {2023}
}

@misc{geminiteam2024gemini,
 abstract = { and Machel Reid and Nikolay Savinov and Denis Teplyashin and Dmitry and Lepikhin and Timothy Lillicrap and Jean-baptiste Alayrac and Radu Soricut and Angeliki Lazaridou and Orhan Firat and Julian Schrittwieser and Ioannis Antonoglou and Rohan Anil and Sebastian Borgeaud and Andrew Dai and Katie Millican and Ethan Dyer and Mia Glaese and Thibault Sottiaux and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and James Molloy and Jilin Chen and Michael Isard and Paul Barham and Tom Hennigan and Ross McIlroy and Melvin Johnson and Johan Schalkwyk and Eli Collins and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Clemens Meyer and Gregory Thornton and Zhen Yang and Henryk Michalewski and Zaheer Abbas and Nathan Schucher and Ankesh Anand and Richard Ives and James Keeling and Karel Lenc and Salem Haykal and Siamak Shakeri and Pranav Shyam and Aakanksha Chowdhery and Roman Ring and Stephen Spencer and Eren Sezener and Luke Vilnis and Oscar Chang and Nobuyuki Morioka and George Tucker and Ce Zheng and Oliver Woodman and Nithya Attaluri and Tomas Kocisky and Evgenii Eltyshev and Xi Chen and Timothy Chung and Vittorio Selo and Siddhartha Brahma and Petko Georgiev and Ambrose Slone and Zhenkai Zhu and James Lottes and Siyuan Qiao and Ben Caine and Sebastian Riedel and Alex Tomala and Martin Chadwick and Juliette Love and Peter Choy and Sid Mittal and Neil Houlsby and Yunhao Tang and Matthew Lamm and Libin Bai and Qiao Zhang and Luheng He and Yong Cheng and Peter Humphreys and Yujia Li and Sergey Brin and Albin Cassirer and Yingjie Miao and Lukas Zilka and Taylor Tobin and Kelvin Xu and Lev Proleev and Daniel Sohn and Alberto Magni and Lisa Anne Hendricks and Isabel Gao and Santiago Ontanon and Oskar Bunyan and Nathan Byrd and Abhanshu Sharma and Biao Zhang and Mario Pinto and Rishika Sinha and Harsh Mehta and Dawei Jia and Sergi Caelles and Albert Webson and Alex Morris and Becca Roelofs and Yifan Ding and Robin Strudel and Xuehan Xiong and Marvin Ritter and Mostafa Dehghani and Rahma Chaabouni and Abhijit Karmarkar and Guangda Lai and Fabian Mentzer and Bibo Xu and YaGuang Li and Yujing Zhang and Tom Le Paine and Alex Goldin and Behnam Neyshabur and Kate Baumli and Anselm Levskaya and Michael Laskin and Wenhao Jia and Jack W. Rae and Kefan Xiao and Antoine He and Skye Giordano and Lakshman Yagati and Jean-Baptiste Lespiau and Paul Natsev and Sanjay Ganapathy and Fangyu Liu and Danilo Martins and Nanxin Chen and Yunhan Xu and Megan Barnes and Rhys May and Arpi Vezer and Junhyuk Oh and Ken Franko and Sophie Bridgers and Ruizhe Zhao and Boxi Wu and Basil Mustafa and Sean Sechrist and Emilio Parisotto and Thanumalayan Sankaranarayana Pillai and Chris Larkin and Chenjie Gu and Christina Sorokin and Maxim Krikun and Alexey Guseynov and Jessica Landon and Romina Datta and Alexander Pritzel and Phoebe Thacker and Fan Yang and Kevin Hui and Anja Hauth and Chih-Kuan Yeh and David Barker and Justin Mao-Jones and Sophia Austin and Hannah Sheahan and Parker Schuh and James Svensson and Rohan Jain and Vinay Ramasesh and Anton Briukhov and Da-Woon Chung and Tamara von Glehn and Christina Butterfield and Priya Jhakra and Matthew Wiethoff and Justin Frye and Jordan Grimstad and Beer Changpinyo and Charline Le Lan and Anna Bortsova and Yonghui Wu and Paul Voigtlaender and Tara Sainath and Shane Gu and Charlotte Smith and Will Hawkins and Kris Cao and James Besley and Srivatsan Srinivasan and Mark Omernick and Colin Gaffney and Gabriela Surita and Ryan Burnell and Bogdan Damoc and Junwhan Ahn and Andrew Brock and Mantas Pajarskas and Anastasia Petrushkina and Seb Noury and Lorenzo Blanco and Kevin Swersky and Arun Ahuja and Thi Avrahami and Vedant Misra and Raoul de Liedekerke and Mariko Iinuma and Alex Polozov and Sarah York and George van den Driessche and Paul Michel and Justin Chiu and Rory Blevins and Zach Gleicher and Adrià Recasens and Alban Rrustemi and Elena Gribovskaya and Aurko Roy and Wiktor Gworek and Sébastien M. R. Arnold and Lisa Lee and James Lee-Thorp and Marcello Maggioni and Enrique Piqueras and Kartikeya Badola and Sharad Vikram and Lucas Gonzalez and Anirudh Baddepudi and Evan Senter and Jacob Devlin and James Qin and Michael Azzam and Maja Trebacz and Martin Polacek and Kashyap Krishnakumar and Shuo-yiin Chang and Matthew Tung and Ivo Penchev and Rishabh Joshi and Kate Olszewska and Carrie Muir and Mateo Wirth and Ale Jakse Hartman and Josh Newlan and Sheleem Kashem and Vijay Bolina and Elahe Dabir and Joost van Amersfoort and Zafarali Ahmed and James Cobon-Kerr and Aishwarya Kamath and Arnar Mar Hrafnkelsson and Le Hou and Ian Mackinnon and Alexandre Frechette and Eric Noland and Xiance Si and Emanuel Taropa and Dong Li and Phil Crone and Anmol Gulati and Sébastien Cevey and Jonas Adler and Ada Ma and David Silver and Simon Tokumine and Richard Powell and Stephan Lee and Kiran Vodrahalli and Samer Hassan and Diana Mincu and Antoine Yang and Nir Levine and Jenny Brennan and Mingqiu Wang and Sarah Hodkinson and Jeffrey Zhao and Josh Lipschultz and Aedan Pope and Michael B. Chang and Cheng Li and Laurent El Shafey and Michela Paganini and Sholto Douglas and Bernd Bohnet and Fabio Pardo and Seth Odoom and Mihaela Rosca and Cicero Nogueira dos Santos and Kedar Soparkar and Arthur Guez and Tom Hudson and Steven Hansen and Chulayuth Asawaroengchai and Ravi Addanki and Tianhe Yu and Wojciech Stokowiec and Mina Khan and Justin Gilmer and Jaehoon Lee and Carrie Grimes Bostock and Keran Rong and Jonathan Caton and Pedram Pejman and Filip Pavetic and Geoff Brown and Vivek Sharma and Mario Lučić and Rajkumar Samuel and Josip Djolonga and Amol Mandhane and Lars Lowe Sjösund and Elena Buchatskaya and Elspeth White and Natalie Clay and Jiepu Jiang and Hyeontaek Lim and Ross Hemsley and Zeyncep Cankara and Jane Labanowski and Nicola De Cao and David Steiner and Sayed Hadi Hashemi and Jacob Austin and Anita Gergely and Tim Blyth and Joe Stanton and Kaushik Shivakumar and Aditya Siddhant and Anders Andreassen and Carlos Araya and Nikhil Sethi and Rakesh Shivanna and Steven Hand and Ankur Bapna and Ali Khodaei and Antoine Miech and Garrett Tanzer and Andy Swing and Shantanu Thakoor and Lora Aroyo and Zhufeng Pan and Zachary Nado and Jakub Sygnowski and Stephanie Winkler and Dian Yu and Mohammad Saleh and Loren Maggiore and Yamini Bansal and Xavier Garcia and Mehran Kazemi and Piyush Patil and Ishita Dasgupta and Iain Barr and Minh Giang and Thais Kagohara and Ivo Danihelka and Amit Marathe and Vladimir Feinberg and Mohamed Elhawaty and Nimesh Ghelani and Dan Horgan and Helen Miller and Lexi Walker and Richard Tanburn and Mukarram Tariq and Disha Shrivastava and Fei Xia and Qingze Wang and Chung-Cheng Chiu and Zoe Ashwood and Khuslen Baatarsukh and Sina Samangooei and Raphaël Lopez Kaufman and Fred Alcober and Axel Stjerngren and Paul Komarek and Katerina Tsihlas and Anudhyan Boral and Ramona Comanescu and Jeremy Chen and Ruibo Liu and Chris Welty and Dawn Bloxwich and Charlie Chen and Yanhua Sun and Fangxiaoyu Feng and Matthew Mauger and Xerxes Dotiwalla and Vincent Hellendoorn and Michael Sharman and Ivy Zheng and Krishna Haridasan and Gabe Barth-Maron and Craig Swanson and Dominika Rogozińska and Alek Andreev and Paul Kishan Rubenstein and Ruoxin Sang and Dan Hurt and Gamaleldin Elsayed and Renshen Wang and Dave Lacey and Anastasija Ilić and Yao Zhao and Adam Iwanicki and Alejandro Lince and Alexander Chen and Christina Lyu and Carl Lebsack and Jordan Griffith and Meenu Gaba and Paramjit Sandhu and Phil Chen and Anna Koop and Ravi Rajwar and Soheil Hassas Yeganeh and Solomon Chang and Rui Zhu and Soroush Radpour and Elnaz Davoodi and Ving Ian Lei and Yang Xu and Daniel Toyama and Constant Segal and Martin Wicke and Hanzhao Lin and Anna Bulanova and Adrià Puigdomènech Badia and Nemanja Rakićević and Pablo Sprechmann and Angelos Filos and Shaobo Hou and Víctor Campos and Nora Kassner and Devendra Sachan and Meire Fortunato and Chimezie Iwuanyanwu and Vitaly Nikolaev and Balaji Lakshminarayanan and Sadegh Jazayeri and Mani Varadarajan and Chetan Tekur and Doug Fritz and Misha Khalman and David Reitter and Kingshuk Dasgupta and Shourya Sarcar and Tina Ornduff and Javier Snaider and Fantine Huot and Johnson Jia and Rupert Kemp and Nejc Trdin and Anitha Vijayakumar and Lucy Kim and Christof Angermueller and Li Lao and Tianqi Liu and Haibin Zhang and David Engel and Somer Greene and Anaïs White and Jessica Austin and Lilly Taylor and Shereen Ashraf and Dangyi Liu and Maria Georgaki and Irene Cai and Yana Kulizhskaya and Sonam Goenka and Brennan Saeta and Ying Xu and Christian Frank and Dario de Cesare and Brona Robenek and Harry Richardson and Mahmoud Alnahlawi and Christopher Yew and Priya Ponnapalli and Marco Tagliasacchi and Alex Korchemniy and Yelin Kim and Dinghua Li and Bill Rosgen and Kyle Levin and Jeremy Wiesner and Praseem Banzal and Praveen Srinivasan and Hongkun Yu and Çağlar Ünlü and David Reid and Zora Tung and Daniel Finchelstein and Ravin Kumar and Andre Elisseeff and Jin Huang and Ming Zhang and Ricardo Aguilar and Mai Giménez and Jiawei Xia and Olivier Dousse and Willi Gierke and Damion Yates and Komal Jalan and Lu Li and Eri Latorre-Chimoto and Duc Dung Nguyen and Ken Durden and Praveen Kallakuri and Yaxin Liu and Matthew Johnson and Tomy Tsai and Alice Talbert and Jasmine Liu and Alexander Neitz and Chen Elkind and Marco Selvi and Mimi Jasarevic and Livio Baldini Soares and Albert Cui and Pidong Wang and Alek Wenjiao Wang and Xinyu Ye and Krystal Kallarackal and Lucia Loher and Hoi Lam and Josef Broder and Dan Holtmann-Rice and Nina Martin and Bramandia Ramadhana and Mrinal Shukla and Sujoy Basu and Abhi Mohan and Nick Fernando and Noah Fiedel and Kim Paterson and Hui Li and Ankush Garg and Jane Park and DongHyun Choi and Diane Wu and Sankalp Singh and Zhishuai Zhang and Amir Globerson and Lily Yu and John Carpenter and Félix de Chaumont Quitry and Carey Radebaugh and Chu-Cheng Lin and Alex Tudor and Prakash Shroff and Drew Garmon and Dayou Du and Neera Vats and Han Lu and Shariq Iqbal and Alex Yakubovich and Nilesh Tripuraneni and James Manyika and Haroon Qureshi and Nan Hua and Christel Ngani and Maria Abi Raad and Hannah Forbes and Jeff Stanway and Mukund Sundararajan and Victor Ungureanu and Colton Bishop and Yunjie Li and Balaji Venkatraman and Bo Li and Chloe Thornton and Salvatore Scellato and Nishesh Gupta and Yicheng Wang and Ian Tenney and Xihui Wu and Ashish Shenoy and Gabriel Carvajal and Diana Gage Wright and Ben Bariach and Zhuyun Xiao and Peter Hawkins and Sid Dalmia and Clement Farabet and Pedro Valenzuela and Quan Yuan and Ananth Agarwal and Mia Chen and Wooyeol Kim and Brice Hulse and Nandita Dukkipati and Adam Paszke and Andrew Bolt and Kiam Choo and Jennifer Beattie and Jennifer Prendki and Harsha Vashisht and Rebeca Santamaria-Fernandez and Luis C. Cobo and Jarek Wilkiewicz and David Madras and Ali Elqursh and Grant Uy and Kevin Ramirez and Matt Harvey and Tyler Liechty and Heiga Zen and Jeff Seibert and Clara Huiyi Hu and Andrey Khorlin and Maigo Le and Asaf Aharoni and Megan Li and Lily Wang and Sandeep Kumar and Norman Casagrande and Jay Hoover and Dalia El Badawy and David Soergel and Denis Vnukov and Matt Miecnikowski and Jiri Simsa and Praveen Kumar and Thibault Sellam and Daniel Vlasic and Samira Daruki and Nir Shabat and John Zhang and Guolong Su and Jiageng Zhang and Jeremiah Liu and Yi Sun and Evan Palmer and Alireza Ghaffarkhah and Xi Xiong and Victor Cotruta and Michael Fink and Lucas Dixon and Ashwin Sreevatsa and Adrian Goedeckemeyer and Alek Dimitriev and Mohsen Jafari and Remi Crocker and Nicholas FitzGerald and Aviral Kumar and Sanjay Ghemawat and Ivan Philips and Frederick Liu and Yannie Liang and Rachel Sterneck and Alena Repina and Marcus Wu and Laura Knight and Marin Georgiev and Hyo Lee and Harry Askham and Abhishek Chakladar and Annie Louis and Carl Crous and Hardie Cate and Dessie Petrova and Michael Quinn and Denese Owusu-Afriyie and Achintya Singhal and Nan Wei and Solomon Kim and Damien Vincent and Milad Nasr and Christopher A. Choquette-Choo and Reiko Tojo and Shawn Lu and Diego de Las Casas and Yuchung Cheng and Tolga Bolukbasi and Katherine Lee and Saaber Fatehi and Rajagopal Ananthanarayanan and Miteyan Patel and Charbel Kaed and Jing Li and Shreyas Rammohan Belle and Zhe Chen and Jaclyn Konzelmann and Siim Põder and Roopal Garg and Vinod Koverkathu and Adam Brown and Chris Dyer and Rosanne Liu and Azade Nova and Jun Xu and Alanna Walton and Alicia Parrish and Mark Epstein and Sara McCarthy and Slav Petrov and Demis Hassabis and Koray Kavukcuoglu and Jeffrey Dean and Oriol Vinyals},
 archiveprefix = {arXiv},
 author = {Team Gemini},
 eprint = {2403.05530},
 primaryclass = {cs.CL},
 title = {Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
 year = {2024}
}

@inproceedings{geva-etal-2019-modeling,
 address = {Hong Kong, China},
 author = {Geva, Mor  and
Goldberg, Yoav  and
Berant, Jonathan},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 doi = {10.18653/v1/D19-1107},
 editor = {Inui, Kentaro  and
Jiang, Jing  and
Ng, Vincent  and
Wan, Xiaojun},
 month = {November},
 pages = {1161--1166},
 publisher = {Association for Computational Linguistics},
 title = {Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets},
 url = {https://aclanthology.org/D19-1107},
 year = {2019}
}

@misc{grattafiori2024llama3herdmodels,
 archiveprefix = {arXiv},
 author = {Llama and : and Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and et al.},
 eprint = {2407.21783},
 primaryclass = {cs.AI},
 title = {The Llama 3 Herd of Models},
 url = {https://arxiv.org/abs/2407.21783},
 year = {2024}
}

@inproceedings{gururangan-etal-2018-annotation,
 address = {New Orleans, Louisiana},
 author = {Gururangan, Suchin  and
Swayamdipta, Swabha  and
Levy, Omer  and
Schwartz, Roy  and
Bowman, Samuel  and
Smith, Noah A.},
 booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
 doi = {10.18653/v1/N18-2017},
 editor = {Walker, Marilyn  and
Ji, Heng  and
Stent, Amanda},
 month = {June},
 pages = {107--112},
 publisher = {Association for Computational Linguistics},
 title = {Annotation Artifacts in Natural Language Inference Data},
 url = {https://aclanthology.org/N18-2017},
 year = {2018}
}

@article{Hellwig2025DoWS,
 author = {Nils Constantin Hellwig and Jakob Fehle and Udo Kruschwitz and Christian Wolff},
 journal = {ArXiv},
 title = {Do we still need Human Annotators? Prompting Large Language Models for Aspect Sentiment Quad Prediction},
 url = {https://api.semanticscholar.org/CorpusID:276421825},
 volume = {abs/2502.13044},
 year = {2025}
}

@inproceedings{hu-etal-2022-improving-aspect,
 address = {Abu Dhabi, United Arab Emirates},
 author = {Hu, Mengting  and
Wu, Yike  and
Gao, Hang  and
Bai, Yinhao  and
Zhao, Shiwan},
 booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
 doi = {10.18653/v1/2022.emnlp-main.538},
 editor = {Goldberg, Yoav  and
Kozareva, Zornitsa  and
Zhang, Yue},
 month = {December},
 pages = {7889--7900},
 publisher = {Association for Computational Linguistics},
 title = {Improving Aspect Sentiment Quad Prediction via Template-Order Data Augmentation},
 url = {https://aclanthology.org/2022.emnlp-main.538},
 year = {2022}
}

@inproceedings{hu-etal-2023-uncertainty,
 address = {Toronto, Canada},
 author = {Hu, Mengting  and
Bai, Yinhao  and
Wu, Yike  and
Zhang, Zhen  and
Zhang, Liqi  and
Gao, Hang  and
Zhao, Shiwan  and
Huang, Minlie},
 booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
 doi = {10.18653/v1/2023.findings-acl.851},
 editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
 month = {July},
 pages = {13481--13494},
 publisher = {Association for Computational Linguistics},
 title = {Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction},
 url = {https://aclanthology.org/2023.findings-acl.851},
 year = {2023}
}

@inproceedings{jiang-etal-2019-challenge,
 address = {Hong Kong, China},
 author = {Jiang, Qingnan  and
Chen, Lei  and
Xu, Ruifeng  and
Ao, Xiang  and
Yang, Min},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 doi = {10.18653/v1/D19-1654},
 editor = {Inui, Kentaro  and
Jiang, Jing  and
Ng, Vincent  and
Wan, Xiaojun},
 month = {November},
 pages = {6280--6285},
 publisher = {Association for Computational Linguistics},
 title = {A Challenge Dataset and Effective Models for Aspect-Based Sentiment Analysis},
 url = {https://aclanthology.org/D19-1654},
 year = {2019}
}

@misc{li2024agentsneed,
 archiveprefix = {arXiv},
 author = {Junyou Li and Qin Zhang and Yangbin Yu and Qiang Fu and Deheng Ye},
 eprint = {2402.05120},
 primaryclass = {cs.CL},
 title = {More Agents Is All You Need},
 url = {https://arxiv.org/abs/2402.05120},
 year = {2024}
}

@article{Namee2022,
 abstract = {This study presents a method of aspect-based sentiment analysis for customer reviews related to hotels. The considered hotel aspects are staff attentiveness, room cleanliness, value for money and convenience of location. The proposed method consists of two main components. The first component is used to assemble relevant sentences for each hotel aspect into relevant clusters of hotel aspects using BM25. We developed a corpus of keywords called the Keywords of Hotel Aspect (KoHA) Corpus, and the keywords of each aspect were used as queries to assemble relevant sentences of each hotel aspect into relevant clusters. Finally, customer review sentences in each cluster were classified into positive and negative classes using sentiment classifiers. Two algorithms, Support Vector Machines (SVM) with a linear and a RBF kernel, and Convolutional Neural Network (CNN) were applied to develop the sentiment classifier models. The model based on SVM with a linear kernel returned better results than other models with an AUC score of 0.87. Therefore, this model was chosen for the sentiment classification stage. The proposed method was evaluated using recall, precision and F1 with satisfactory results at 0.85, 0.87 and 0.86, respectively. Our proposed method provided an overview of customer feelings based on score, and also provided reasons why customers liked or disliked each aspect of the hotel. The best model from the proposed method was used to compare with a state-of-the-art model. The results show that our method increased recall, precision, and F1 scores by 2.44\%, 2.50\% and 1.84\%, respectively.},
 author = {Khanista Namee and Jantima Polpinij and Bancha Luaphol},
 doi = {10.55003/cast.2022.02.23.008},
 journal = {Current Applied Science and Technology},
 keywords = {sentiment analysis, aspect level, Word2Vec, support vector machines, convolutional neural network, BM25},
 number = {2},
 pages = {Published: Aug 15, 2022},
 title = {A Hybrid Approach for Aspect-based Sentiment Analysis: A Case Study of Hotel Reviews},
 url = {https://li01.tci-thaijo.org/index.php/cast/article/view/253287},
 volume = {23},
 year = {2023}
}

@misc{openai2024gpt4,
 abstract = {and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
 archiveprefix = {arXiv},
 author = {OpenAI},
 eprint = {2303.08774},
 primaryclass = {cs.CL},
 title = {{GPT}-4 Technical Report},
 year = {2024}
}

@article{PAULLADA2021100336,
 abstract = {Summary
In this work, we survey a breadth of literature that has revealed the limitations of predominant practices for dataset collection and use in the field of machine learning. We cover studies that critically review the design and development of datasets with a focus on negative societal impacts and poor outcomes for system performance. We also cover approaches to filtering and augmenting data and modeling techniques aimed at mitigating the impact of bias in datasets. Finally, we discuss works that have studied data practices, cultures, and disciplinary norms and discuss implications for the legal, ethical, and functional challenges the field continues to face. Based on these findings, we advocate for the use of both qualitative and quantitative approaches to more carefully document and analyze datasets during the creation and usage phases.},
 author = {Amandalynne Paullada and Inioluwa Deborah Raji and Emily M. Bender and Emily Denton and Alex Hanna},
 doi = {https://doi.org/10.1016/j.patter.2021.100336},
 issn = {2666-3899},
 journal = {Patterns},
 keywords = {datasets machine learning},
 number = {11},
 pages = {100336},
 title = {Data and its (dis)contents: A survey of dataset development and use in machine learning research},
 url = {https://www.sciencedirect.com/science/article/pii/S2666389921001847},
 volume = {2},
 year = {2021}
}

@inproceedings{pegasus,
 abstract = {Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization. However, pre-training objectives tailored for abstractive text summarization have not been explored. Furthermore there is a lack of systematic evaluation across diverse domains. In this work, we propose pretraining large Transformer-based encoder-decoder models on massive text corpora with a new self-supervised objective. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an extractive summary. We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills. Experiments demonstrate it achieves state-of-the-art performance on all 12 downstream datasets measured by ROUGE scores. Our model also shows surprising performance on low-resource summarization, surpassing previous state-of-the-art results on 6 datasets with only 1000 examples. Finally we validated our results using human evaluation and show that our model summaries achieve human performance on multiple datasets.},
 articleno = {1051},
 author = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J.},
 booktitle = {Proceedings of the 37th International Conference on Machine Learning},
 numpages = {12},
 publisher = {JMLR.org},
 series = {ICML 2020},
 title = {PEGASUS: pre-training with extracted gap-sentences for abstractive summarization},
 year = {2020}
}

@inproceedings{peper-etal-2024-shoes,
 abstract = {We explore *implicit opinion extraction* as a new component of aspect-based sentiment analysis (ABSA) systems. Prior work in ABSA has investigated opinion extraction as an important subtask, however, these works only label concise, *explicitly*-stated opinion spans. In this work, we present **Shoes-ACOSI**, a new and challenging ABSA dataset in the e-commerce domain with implicit opinion span annotations, the first of its kind. Shoes-ACOSI builds upon the existing Aspect-Category-Opinion-Sentiment (ACOS) quadruple extraction task, extending the task to quintuple extraction{---}now localizing and differentiating both implicit and explicit opinion. In addition to the new annotation schema, our dataset contains paragraph-length inputs which, importantly, present complex challenges through increased input length, increased number of sentiment expressions, and more mixed-sentiment-polarity examples when compared with existing benchmarks. We quantify the difficulty of our new dataset by evaluating with state-of-the-art fully-supervised and prompted-LLM baselines. We find our dataset presents significant challenges for both supervised models and LLMs, particularly from the new implicit opinion extraction component of the ACOSI task, highlighting the need for continued research into implicit opinion understanding.},
 address = {Miami, Florida, USA},
 author = {Peper, Joseph J  and
Qiu, Wenzhao  and
Bruggeman, Ryan  and
Han, Yi  and
Chehade, Estefania Ciliotta  and
Wang, Lu},
 booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
 doi = {10.18653/v1/2024.findings-emnlp.907},
 editor = {Al-Onaizan, Yaser  and
Bansal, Mohit  and
Chen, Yun-Nung},
 month = {November},
 pages = {15477--15490},
 publisher = {Association for Computational Linguistics},
 title = {Shoes-{ACOSI}: A Dataset for Aspect-Based Sentiment Analysis with Implicit Opinion Extraction},
 url = {https://aclanthology.org/2024.findings-emnlp.907/},
 year = {2024}
}

@article{PING2024126994,
 abstract = {Aspect category sentiment analysis (ACSA) excels at identifying the aspect categories and corresponding sentiments involved in a sentence, regardless of whether the aspect terms are explicitly mentioned or not. However, current methods tend to overinflate the original data, resulting in the introduction of unnecessary information, and fail to capture the inter-task relationship sufficiently. This paper presents a new method termed the prompt-based joint model (PBJM) to address these complications. PBJM treats the sentiment polarity prediction as binary classification and leverages a natural language prompt template, a concise sentence that guides the model to perform aspect category identification subtask and curtails the need for data augmentation. The two subtasks are jointly trained in pre-trained language models (PLMs) to capture their correlation. Further, the attention mechanism for aspect categories enables the model to concentrate selectively on significant features such as phrases and words during the predictions. In addition, the verbalizer employs a set of parameters to balance the weight of each label word while projecting between the label space and the label words space. Through experiments on four datasets, our model demonstrated remarkable performance in detecting category-sentiment pairs.},
 author = {Zhichao Ping and Guoming Sang and Zhi Liu and Yijia Zhang},
 doi = {https://doi.org/10.1016/j.neucom.2023.126994},
 issn = {0925-2312},
 journal = {Neurocomputing},
 keywords = {Prompt-based learning, Aspect category sentiment analysis, Attention mechanism},
 title = {Aspect category sentiment analysis based on prompt-based learning with attention mechanism},
 url = {https://www.sciencedirect.com/science/article/pii/S0925231223011177},
 volume = {565},
 year = {2024}
}

@inproceedings{pontiki-etal-2016-semeval,
 address = {San Diego, California},
 author = {Pontiki, Maria  and
Galanis, Dimitris  and
Papageorgiou, Haris  and
Androutsopoulos, Ion  and
Manandhar, Suresh  and
AL-Smadi, Mohammad  and
Al-Ayyoub, Mahmoud  and
Zhao, Yanyan  and
Qin, Bing  and
De Clercq, Orph{\'e}e  and
Hoste, V{\'e}ronique  and
Apidianaki, Marianna  and
Tannier, Xavier  and
Loukachevitch, Natalia  and
Kotelnikov, Evgeniy  and
Bel, Nuria  and
Jim{\'e}nez-Zafra, Salud Mar{\'\i}a  and
Eryi{\u{g}}it, G{\"u}l{\c{s}}en},
 booktitle = {Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016)},
 doi = {10.18653/v1/S16-1002},
 editor = {Bethard, Steven  and
Carpuat, Marine  and
Cer, Daniel  and
Jurgens, David  and
Nakov, Preslav  and
Zesch, Torsten},
 month = {June},
 pages = {19--30},
 publisher = {Association for Computational Linguistics},
 title = {{S}em{E}val-2016 Task 5: Aspect Based Sentiment Analysis},
 url = {https://aclanthology.org/S16-1002},
 year = {2016}
}

@misc{promptstability,
 archiveprefix = {arXiv},
 author = {Christopher Barrie and Elli Palaiologou and Petter Törnberg},
 eprint = {2407.02039},
 primaryclass = {cs.CL},
 title = {Prompt Stability Scoring for Text Annotation with Large Language Models},
 url = {https://arxiv.org/abs/2407.02039},
 year = {2025}
}

@book{Pustejovsky_Stubbs_2013,
 author = {Pustejovsky, J. and Stubbs, Amber},
 place = {Sebastopol, CA},
 publisher = {O’Reilly Media, Inc},
 title = {Natural language annotation for machine learning},
 year = {2013}
}

@misc{qwen2025qwen25technicalreport,
 archiveprefix = {arXiv},
 author = {Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
 eprint = {2412.15115},
 primaryclass = {cs.CL},
 title = {Qwen2.5 Technical Report},
 url = {https://arxiv.org/abs/2412.15115},
 year = {2025}
}

@inproceedings{reimers-gurevych-2019-sentence,
 address = {Hong Kong, China},
 author = {Reimers, Nils  and
Gurevych, Iryna},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 doi = {10.18653/v1/D19-1410},
 editor = {Inui, Kentaro  and
Jiang, Jing  and
Ng, Vincent  and
Wan, Xiaojun},
 month = {November},
 pages = {3982--3992},
 publisher = {Association for Computational Linguistics},
 title = {Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks},
 url = {https://aclanthology.org/D19-1410},
 year = {2019}
}

@inproceedings{rink-etal-2024-aspect,
 address = {St. Julian{'}s, Malta},
 author = {Rink, Lois  and
Meijdam, Job  and
Graus, David},
 booktitle = {Proceedings of the First Workshop on Natural Language Processing for Human Resources (NLP4HR 2024)},
 editor = {Hruschka, Estevam  and
Lake, Thom  and
Otani, Naoki  and
Mitchell, Tom},
 month = {March},
 pages = {16--26},
 publisher = {Association for Computational Linguistics},
 title = {Aspect-Based Sentiment Analysis for Open-Ended {HR} Survey Responses},
 url = {https://aclanthology.org/2024.nlp4hr-1.2},
 year = {2024}
}

@misc{roberta,
 archiveprefix = {arXiv},
 author = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
 eprint = {1907.11692},
 primaryclass = {cs.CL},
 title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
 url = {https://arxiv.org/abs/1907.11692},
 year = {2019}
}

@inproceedings{samuel-etal-2025-towards,
 abstract = {As large language models achieve increasingly impressive results, questions arise about whether such performance is from generalizability or mere data memorization. Thus, numerous data contamination detection methods have been proposed. However, these approaches are often validated with traditional benchmarks and early-stage LLMs, leaving uncertainty about their effectiveness when evaluating state-of-the-art LLMs on the contamination of more challenging benchmarks. To address this gap and provide a dual investigation of SOTA LLM contamination status and detection method robustness, we evaluate five contamination detection approaches with four state-of-the-art LLMs across eight challenging datasets often used in modern LLM evaluation. Our analysis reveals that (1) Current methods have non-trivial limitations in their assumptions and practical applications; (2) Notable difficulties exist in detecting contamination introduced during instruction fine-tuning with answer augmentation; and (3) Limited consistencies between SOTA contamination detection techniques. These findings highlight the complexity of contamination detection in advanced LLMs and the urgent need for further research on robust and generalizable contamination evaluation.},
 address = {Abu Dhabi, UAE},
 author = {Samuel, Vinay  and
Zhou, Yue  and
Zou, Henry Peng},
 booktitle = {Proceedings of the 31st International Conference on Computational Linguistics},
 editor = {Rambow, Owen  and
Wanner, Leo  and
Apidianaki, Marianna  and
Al-Khalifa, Hend  and
Eugenio, Barbara Di  and
Schockaert, Steven},
 month = {January},
 pages = {5058--5070},
 publisher = {Association for Computational Linguistics},
 title = {Towards Data Contamination Detection for Modern Large Language Models: Limitations, Inconsistencies, and Oracle Challenges},
 url = {https://aclanthology.org/2025.coling-main.338/},
 year = {2025}
}

@article{scikit-learn,
 abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
 author = {Pedregosa, Fabian and Varoquaux, Ga\"{e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, \'{E}douard},
 issn = {1532-4435},
 issue_date = {2/1/2011},
 journal = {J. Mach. Learn. Res.},
 month = {November},
 numpages = {6},
 pages = {2825–2830},
 publisher = {JMLR.org},
 title = {Scikit-learn: Machine Learning in Python},
 volume = {12},
 year = {2011}
}

@misc{shorinwa2024surveyuncertaintyquantificationlarge,
 archiveprefix = {arXiv},
 author = {Ola Shorinwa and Zhiting Mei and Justin Lidard and Allen Z. Ren and Anirudha Majumdar},
 eprint = {2412.05563},
 primaryclass = {cs.CL},
 title = {A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions},
 url = {https://arxiv.org/abs/2412.05563},
 year = {2024}
}

@article{spearman1904,
 author = {Charles Spearman},
 journal = {American Journal of Psychology},
 pages = {72--101},
 title = {The proof and measurement of association between two things},
 volume = {15},
 year = {1904}
}

@article{t5,
 abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
 articleno = {140},
 author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
 issn = {1532-4435},
 issue_date = {January 2020},
 journal = {J. Mach. Learn. Res.},
 keywords = {transfer learning, natural language processing, multi-task learning, attention based models, deep learning},
 month = {jan},
 number = {1},
 numpages = {67},
 publisher = {JMLR.org},
 title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
 volume = {21},
 year = {2020}
}

@article{Wan_Yang_Du_Liu_Qi_Pan_2020,
 abstractnote = {&lt;p&gt;&lt;em&gt;Aspect-based sentiment analysis&lt;/em&gt; (ABSA) aims to detect the targets (which are composed by continuous words), aspects and sentiment polarities in text. Published datasets from SemEval-2015 and SemEval-2016 reveal that a sentiment polarity depends on both the target and the aspect. However, most of the existing methods consider predicting sentiment polarities from either targets or aspects but not from both, thus they easily make wrong predictions on sentiment polarities. In particular, where the target is implicit, &lt;em&gt;i.e.&lt;/em&gt;, it does not appear in the given text, the methods predicting sentiment polarities from targets do not work. To tackle these limitations in ABSA, this paper proposes a novel method for target-aspect-sentiment joint detection. It relies on a pre-trained language model and can capture the dependence on both targets and aspects for sentiment prediction. Experimental results on the SemEval-2015 and SemEval-2016 restaurant datasets show that the proposed method achieves a high performance in detecting target-aspect-sentiment triples even for the implicit target cases; moreover, it even outperforms the state-of-the-art methods for those subtasks of target-aspect-sentiment detection that they are competent to.&lt;/p&gt;},
 author = {Wan, Hai and Yang, Yufei and Du, Jianfeng and Liu, Yanan and Qi, Kunxun and Pan, Jeff Z.},
 doi = {10.1609/aaai.v34i05.6447},
 journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
 month = {Apr.},
 number = {05},
 pages = {9122-9129},
 title = {Target-Aspect-Sentiment Joint Detection for Aspect-Based Sentiment Analysis},
 url = {https://ojs.aaai.org/index.php/AAAI/article/view/6447},
 volume = {34},
 year = {2020}
}

@inproceedings{wang-etal-2023-generative,
 address = {Toronto, Canada},
 author = {Wang, An  and
Jiang, Junfeng  and
Ma, Youmi  and
Liu, Ao  and
Okazaki, Naoaki},
 booktitle = {Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)},
 doi = {10.18653/v1/2023.starsem-1.12},
 editor = {Palmer, Alexis  and
Camacho-collados, Jose},
 month = {July},
 pages = {128--140},
 publisher = {Association for Computational Linguistics},
 title = {Generative Data Augmentation for Aspect Sentiment Quad Prediction},
 url = {https://aclanthology.org/2023.starsem-1.12},
 year = {2023}
}

@inproceedings{wang-etal-2023-primacy,
 address = {Singapore},
 author = {Wang, Yiwei  and
Cai, Yujun  and
Chen, Muhao  and
Liang, Yuxuan  and
Hooi, Bryan},
 booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
 doi = {10.18653/v1/2023.emnlp-main.8},
 editor = {Bouamor, Houda  and
Pino, Juan  and
Bali, Kalika},
 month = {December},
 pages = {108--115},
 publisher = {Association for Computational Linguistics},
 title = {Primacy Effect of {C}hat{GPT}},
 url = {https://aclanthology.org/2023.emnlp-main.8},
 year = {2023}
}

@misc{wang2024mixtureofagentsenhanceslargelanguage,
 archiveprefix = {arXiv},
 author = {Junlin Wang and Jue Wang and Ben Athiwaratkun and Ce Zhang and James Zou},
 eprint = {2406.04692},
 primaryclass = {cs.CL},
 title = {Mixture-of-Agents Enhances Large Language Model Capabilities},
 url = {https://arxiv.org/abs/2406.04692},
 year = {2024}
}

@misc{wei2023chainofthought,
 archiveprefix = {arXiv},
 author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
 eprint = {2201.11903},
 primaryclass = {cs.CL},
 title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
 year = {2023}
}

@misc{wei2025dontjustdemoteach,
 archiveprefix = {arXiv},
 author = {Peipei Wei and Dimitris Dimitriadis and Yan Xu and Mingwei Shen},
 eprint = {2502.07165},
 primaryclass = {cs.CL},
 title = {Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification},
 url = {https://arxiv.org/abs/2502.07165},
 year = {2025}
}

@article{Xu2023TheLO,
 author = {Xiancai Xu and Jia-Dong Zhang and Rongchang Xiao and Lei Xiong},
 journal = {ArXiv},
 title = {The Limits of ChatGPT in Extracting Aspect-Category-Opinion-Sentiment Quadruples: A Comparative Analysis},
 url = {https://api.semanticscholar.org/CorpusID:263830120},
 volume = {abs/2310.06502},
 year = {2023}
}

@article{Xu2025,
 abstract = {Aspect Category Sentiment Analysis (ACSA) is a fine-grained sentiment analysis task aimed at predicting the sentiment polarity associated with aspect categories within a sentence. Most existing ACSA methods are based on a given aspect category to locate sentiment words related to it. When irrelevant sentiment words have semantic meaning for the given aspect category, it may cause the problem that sentiment words cannot be matched with aspect categories. To address the aforementioned issue, this paper proposes a novel approach for ACSA utilizing pre-trained Bidirectional Long Short-Term Memory (BiLSTM) and syntax-aware graph attention network. To address the issue of insufficient existing annotated datasets, a method of using transfer learning is proposed. Firstly, the BiLSTM model is used to pre-train on the document-level sentiment analysis dataset, and the obtained pre-training parameters are transferred to the aspect-level task model. Then, a syntax-aware graph attention network model is proposed to make full use of the syntactic structure and semantic information in the text, and combine the knowledge learned in pre-training to achieve the ACSA task. The performance evaluation of this method is carried out on five user comment text datasets, and the comprehensive ablation experiments prove that this method performs best compared with baseline models.},
 author = {Guixian Xu and Zhe Chen and Zixin Zhang},
 doi = {10.1038/s41598-025-86009-8},
 issn = {2045-2322},
 journal = {Scientific Reports},
 title = {Aspect category sentiment analysis based on pre-trained BiLSTM and syntax-aware graph attention network},
 url = {https://doi.org/10.1038/s41598-025-86009-8},
 volume = {15},
 year = {2025}
}

@inproceedings{zhang-etal-2021-aspect-sentiment,
 address = {Online and Punta Cana, Dominican Republic},
 author = {Zhang, Wenxuan  and
Deng, Yang  and
Li, Xin  and
Yuan, Yifei  and
Bing, Lidong  and
Lam, Wai},
 booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
 doi = {10.18653/v1/2021.emnlp-main.726},
 editor = {Moens, Marie-Francine  and
Huang, Xuanjing  and
Specia, Lucia  and
Yih, Scott Wen-tau},
 month = {November},
 pages = {9209--9219},
 publisher = {Association for Computational Linguistics},
 title = {Aspect Sentiment Quad Prediction as Paraphrase Generation},
 url = {https://aclanthology.org/2021.emnlp-main.726},
 year = {2021}
}

@inproceedings{zhang-etal-2021-towards-generative,
 address = {Online},
 author = {Zhang, Wenxuan  and
Li, Xin  and
Deng, Yang  and
Bing, Lidong  and
Lam, Wai},
 booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
 doi = {10.18653/v1/2021.acl-short.64},
 editor = {Zong, Chengqing  and
Xia, Fei  and
Li, Wenjie  and
Navigli, Roberto},
 month = {August},
 pages = {504--510},
 publisher = {Association for Computational Linguistics},
 title = {Towards Generative Aspect-Based Sentiment Analysis},
 url = {https://aclanthology.org/2021.acl-short.64},
 year = {2021}
}

@article{Zhang2023SentimentAI,
 author = {Wenxuan Zhang and Yue Deng and Bing-Quan Liu and Sinno Jialin Pan and Lidong Bing},
 journal = {ArXiv},
 title = {Sentiment Analysis in the Era of Large Language Models: A Reality Check},
 url = {https://api.semanticscholar.org/CorpusID:258866189},
 volume = {abs/2305.15005},
 year = {2023}
}

@inproceedings{zhou-etal-2023-unified-one,
 address = {Toronto, Canada},
 author = {Zhou, Junxian  and
Yang, Haiqin  and
He, Yuxuan  and
Mou, Hao  and
Yang, JunBo},
 booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
 doi = {10.18653/v1/2023.findings-acl.777},
 editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
 month = {July},
 pages = {12249--12265},
 publisher = {Association for Computational Linguistics},
 title = {A Unified One-Step Solution for Aspect Sentiment Quad Prediction},
 url = {https://aclanthology.org/2023.findings-acl.777},
 year = {2023}
}
