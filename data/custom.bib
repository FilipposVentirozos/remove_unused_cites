% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@article{cardealermagazine2024,
  title = {Strong Consumer Demand Sees Used Car Retail Prices Rise in April – Auto Trader},
  author = {John Bowman},
  journal = {Car Dealer Magazine},
  url = {https://cardealermagazine.co.uk/publish/strong-consumer-demand-sees-used-car-retail-prices-rise-in-april-auto-trader/301239},
  year = {2024},
  month = {May},
  day = {1}
}

@article{gbnews2024,
  author = {Hemma Visavadia},
  title = {Buying a car seen as ‘bigger milestone’ than owning a home as high costs see drivers' priorities shift},
  year = {2024},
  journal = {GB News},
  url = {https://www.gbnews.com/lifestyle/cars/buying-car-bigger-milestone-than-owning-home},
  urldate = {2024-05-06}
}

@misc{geminiteam2024gemini,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team et al.},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Llama Team et al.},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}

@article{McHugh2012,
  author       = {Mary L. McHugh},
  title        = {Interrater reliability: {T}he kappa statistic},
  journal      = {Biochemia medica},
  year         = {2012},
  volume       = {22},
  pages        = {276-282},
  doi          = {biochem_med-22-3-276-4},
  publisher    = {Biochem Med (Zagreb)},
  address      = {Croatia},
  issn         = {1330-0962 (Print), 1846-7482 (Electronic)},
  language     = {eng},
  abstract     = {The kappa statistic is frequently used to test interrater reliability. 
                  The importance of rater reliability lies in the fact that it represents the extent to 
                  which the data collected in the study are correct representations of the 
                  variables measured. Measurement of the extent to which data collectors (raters) 
                  assign the same score to the same variable is called interrater reliability. 
                  While there have been a variety of methods to measure interrater reliability, 
                  traditionally it was measured as percent agreement, calculated as the number of 
                  agreement scores divided by the total number of scores. In 1960, Jacob Cohen 
                  critiqued use of percent agreement due to its inability to account for chance 
                  agreement. He introduced the Cohen's kappa, developed to account for the 
                  possibility that raters actually guess on at least some variables due to 
                  uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. 
                  While the kappa is one of the most commonly used statistics to test interrater reliability, 
                  it has limitations. Judgments about what level of kappa should be 
                  acceptable for health research are questioned. Cohen's suggested interpretation 
                  may be too lenient for health related studies because it implies that a score as 
                  low as 0.41 might be acceptable. Kappa and percent agreement are compared, and 
                  levels for both kappa and percent agreement that should be demanded in healthcare 
                  studies are suggested.},
  type         = {Journal Article},
  keywords     = {Data Interpretation, Statistical, Observer Variation, Reproducibility of Results}
}

@article{Hripcsak2005,
  author       = {George Hripcsak and Adam S. Rothschild},
  title        = {Agreement, the f-measure, and reliability in information retrieval},
  journal      = {Journal of the American Medical Informatics Association : JAMIA},
  year         = {2005},
  volume       = {12},
  pages        = {296-298},
  month        = {May-Jun},
  doi          = {10.1197/jamia.M1733},
  publisher    = {J Am Med Inform Assoc},
  address      = {England},
  issn         = {1067-5027 (Print), 1527-974X (Electronic)},
  language     = {eng},
  abstract     = {Information retrieval studies that involve searching the Internet or marking 
                  phrases usually lack a well-defined number of negative cases. This prevents the 
                  use of traditional interrater reliability metrics like the kappa statistic to 
                  assess the quality of expert-generated gold standards. Such studies often 
                  quantify system performance as precision, recall, and F-measure, or as agreement. 
                  It can be shown that the average F-measure among pairs of experts is numerically 
                  identical to the average positive specific agreement among experts and that kappa 
                  approaches these measures as the number of negative cases grows large. Positive 
                  specific agreement-or the equivalent F-measure-may be an appropriate way to 
                  quantify interrater reliability and therefore to assess the reliability of a gold 
                  standard in these studies.},
  type         = {Journal Article},
  funding      = {N01 LM07079/LM/NLM NIH HHS/United States, R01 LM06919/LM/NLM NIH HHS/United States},
  keywords     = {Humans, Information Services, Information Storage and Retrieval, Internet, 
                  Medical Informatics, Observer Variation, Reproducibility of Results}
}

@article{Deleger2012,
  author       = {Louise Deleger and Qi Li and Todd Lingren and Megan Kaiser and Katalin Molnar and Laura Stoutenborough and Michal Kouril and Keith Marsolo and Imre Solti},
  title        = {Building gold standard corpora for medical natural language processing tasks},
  journal      = {Annual Symposium proceedings. AMIA Symposium},
  year         = {2012},
  volume       = {2012},
  pages        = {144-153},
  doi          = {amia_2012_symp_0144},
  publisher    = {AMIA Annu Symp Proc},
  address      = {United States},
  issn         = {1559-4076 (Print), 1942-597X (Electronic)},
  language     = {eng},
  abstract     = {We present the construction of three annotated corpora to serve as gold standards 
                  for medical natural language processing (NLP) tasks. Clinical notes from the 
                  medical record, clinical trial announcements, and FDA drug labels are annotated. 
                  We report high inter-annotator agreements (overall F-measures between 0.8467 and 
                  0.9176) for the annotation of Personal Health Information (PHI) elements for a 
                  de-identification task and of medications, diseases/disorders, and signs/symptoms 
                  for information extraction (IE) task. The annotated corpora of clinical trials 
                  and FDA labels will be publicly released and to facilitate translational NLP 
                  tasks that require cross-corpora interoperability (e.g. clinical trial 
                  eligibility screening) their annotation schemas are aligned with a large scale, 
                  NIH-funded clinical text annotation project.},
  funding      = {5R00LM010227-04/LM/NLM NIH HHS/United States, R21 HD072883/HD/NICHD NIH HHS/United States,
                  K99 LM010227/LM/NLM NIH HHS/United States, R00 LM010227/LM/NLM NIH HHS/United States,
                  UL1 TR000077/TR/NCATS NIH HHS/United States},
  type         = {Journal Article},
  keywords     = {Clinical Trials as Topic, Drug Labeling, Medical Records, Natural Language Processing, Software, United States, United States Food and Drug Administration}
}

 @book{prodigy, 
 	title={Prodigy: A modern and scriptable annotation tool for creating training data for machine learning models}, 
 	url={https://prodi.gy/}, 
 	journal={Prodigy}, 
 	publisher={Explosion}, 
        year={2017},
 	author={Montani, Ines and Honnibal, Matthew}
 } 

@article{JEHANGIR2023100017,
title = {A survey on Named Entity Recognition — datasets, tools, and methodologies},
journal = {Natural Language Processing Journal},
volume = {3},
pages = {100017},
year = {2023},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2023.100017},
url = {https://www.sciencedirect.com/science/article/pii/S2949719123000146},
author = {Basra Jehangir and Saravanan Radhakrishnan and Rahul Agarwal},
keywords = {Natural language processing, Named Entity Recognition, Deep Learning, Convolutional Neural Network, Bidirectional Long Short Term Memory, Recurrent Neural Networks},
abstract = {Natural language processing (NLP) is crucial in the current processing of data because it takes into account many sources, formats, and purposes of data as well as information from various sectors of our economy, government, and private and public lives. We perform a variety of NLP operations on the text in order to complete certain tasks. One of them is NER (Named Entity Recognition). An act of recognizing and categorizing named entities that are presented in a text document is known as named entity recognition. The purpose of NER is to find references of rigid designators in the text which belong to established semantic kinds like a person, place, organization, etc. It acts as a cornerstone for many Information Extraction-related activities. In this work, we present a thorough analysis of several methodologies for NER ranging from unsupervised learning, rule-based, supervised learning, and various Deep Learning based approaches. We examine the most relevant datasets, tools, and deep learning approaches like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Bidirectional Long Short Term Memory, Transfer learning approaches, and numerous other approaches currently being used in present-day NER problem environments and their applications. Finally, we outline the difficulties NER systems encounter and future directions.}
}


@article{G2023120440,
title = {AGRONER: An unsupervised agriculture named entity recognition using weighted distributional semantic model},
journal = {Expert Systems with Applications},
volume = {229},
pages = {120440},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120440},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423009429},
author = {Veena G. and Vani Kanjirangat and Deepa Gupta},
keywords = {Unsupervised approach, Named entity recognition, BERT, Agriculture, Topic modeling, LDA},
abstract = {In this work, we propose a novel weighted distributional semantic model for unsupervised Named Entity Recognition (NER) in domain specific texts, specifically focusing on agricultural domain. Developing accurate agriculture NER models requires overcoming several challenges, including the lack of annotated data, domain-specific vocabulary, entity ambiguity, and contextual variation. The proposed approach is completely unsupervised and utilizes an extended BERT model with LDA topic modeling (exBERT_LDA+) for NER. The proposed Agricultural Named Entity Recognition (AGRONER) model, focuses on identifying six major entities, disease, soil, pathogen, pesticide, crops, and place. The existing four entities are recognized using the proposed algorithm while we utilize the AGROVOC dictionary for crops and Geocoding APIs for Place entities. Due to the absence of a benchmark dataset in the agriculture domain, we created a corpus of 30,000 sentences extracted from recognized agriculture sites. For the evaluation, we used a test corpus with 700 sentences that include 1690 entity names. The labeled entities were then manually checked to evaluate the prediction accuracy. The proposed approach presents a macro average F-measure of 80.43%, which is quite promising for an unsupervised domain specific entity labeling. We performed ablations studies, where the proposed model exhibited a relative percentage improvement of 31.56%, 26.11% F-measure when compared to BERT without LDA (BERT_LDA−) and extended BERT without LDA (exBERT_LDA−)models, respectively. Experimental results show the efficacy of the proposed approach in labeling the named entities in an unsupervised set-up for the agricultural domain. Further, the approach can be easily extended to recognize more domain-specific entities.11We plan to release the corpus created and the codes for replications.}
}


@INPROCEEDINGS{10499162,
  author={Hu, Songhua and Ma, Ruhu},
  booktitle={2024 4th International Conference on Neural Networks, Information and Communication Engineering (NNICE)}, 
  title={Named Entity Recognition of Automotive Parts Based on RoBERTa-CRF Model}, 
  year={2024},
  volume={},
  number={},
  pages={604-612},
  keywords={Training;Deep learning;Semantics;Knowledge graphs;Data augmentation;Data models;Question answering (information retrieval);Named entity recognition(NER);Natural language processing(NLP);Pre-trained models;Automotive accessory},
  doi={10.1109/NNICE61279.2024.10499162}}


@article{Molineux2018UsingAR,
  title={Using action research for change in organizations: processes, reflections and outcomes},
  author={John Molineux},
  journal={Journal of Work-Applied Management},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:158416550}
}

@inproceedings{10.1145/2962695.2962707,
author = {Jabbari, Ramtin and bin Ali, Nauman and Petersen, Kai and Tanveer, Binish},
title = {What is {D}ev{O}ps? {A} Systematic Mapping Study on Definitions and Practices},
year = {2016},
isbn = {9781450341349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2962695.2962707},
doi = {10.1145/2962695.2962707},
booktitle = {Proceedings of the Scientific Workshop Proceedings of XP2016},
pages = {1-11},
articleno = {12},
numpages = {11},
keywords = {Software development method, DevOps practice, DevOps definition},
location = {Edinburgh, Scotland, UK},
series = {XP Workshops}
}


@misc{openai2024gpt4,
      title={{GPT}-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      abstract={and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph}
}


@article{li2020survey,
  title={A survey on deep learning for named entity recognition},
  author={Li, Jing and Sun, Aixin and Han, Jianglei and Li, Chenliang},
  journal={IEEE transactions on knowledge and data engineering},
  volume={34},
  number={1},
  pages={50--70},
  year={2020},
  publisher={IEEE}
}






@InProceedings{hanh-2021-named,
author="Hanh, Tran Thi Hong
and Doucet, Antoine
and Sidere, Nicolas
and Moreno, Jose G.
and Pollak, Senja",
editor="Ke, Hao-Ren
and Lee, Chei Sian
and Sugiyama, Kazunari",
title="Named Entity Recognition Architecture Combining Contextual and Global Features",
booktitle="Towards Open and Trustworthy Digital Societies",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="264--276",
}

@misc{wang2023gptnernamedentityrecognition,
      title={GPT-NER: Named Entity Recognition via Large Language Models}, 
      author={Shuhe Wang and Xiaofei Sun and Xiaoya Li and Rongbin Ouyang and Fei Wu and Tianwei Zhang and Jiwei Li and Guoyin Wang},
      year={2023},
      eprint={2304.10428},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.10428}, 
}


@misc{wolf2020huggingfacestransformersstateoftheartnatural,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.03771}, 
}

@inproceedings{
he2021deberta,
title={DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION},
author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=XPZIaotutsD}
}

@misc{he2021debertav3,
      title={DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing}, 
      author={Pengcheng He and Jianfeng Gao and Weizhu Chen},
      year={2021},
      eprint={2111.09543},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{keraghel2024recentadvancesnamedentity,
      title={Recent Advances in Named Entity Recognition: A Comprehensive Survey and Comparative Study}, 
      author={Imed Keraghel and Stanislas Morbieu and Mohamed Nadif},
      year={2024},
      eprint={2401.10825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.10825}, 
}